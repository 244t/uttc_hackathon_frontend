# uttc_hackathon_frontend

ハッカソンのフロントエンド用のリポジトリ

## ディレクトリ構成について

## MUI
[アイコンはこちら](https://mui.com/material-ui/material-icons/)

## gemini
投稿内容の悪意や炎上しやすさを測定するために、GeminiのようなAIを活用することは可能です。以下のようなアプローチを考えられます。

1. **感情分析**:
   - 投稿内容に対して感情分析を行い、ポジティブ、ネガティブ、中立のスコアを生成します。特にネガティブな感情が強い場合、悪意や炎上の可能性が高いと判断できます。

2. **トピックモデリング**:
   - 投稿の内容を解析して、どのトピックに関連しているかを特定します。特定のトピック（例：政治、宗教、社会問題など）は炎上しやすいため、関連する投稿には注意が必要です。

3. **過去のデータ分析**:
   - 過去に炎上した投稿のデータを学習させ、似たような特徴を持つ新しい投稿を特定することができます。これにより、炎上のリスクを予測できます。

4. **ユーザー行動の分析**:
   - 特定のユーザーの投稿に対する反応（リプライ、リツイート、いいねなど）を分析し、過去に炎上した場合のパターンを見つけ出すことができます。

5. **悪意のある用語やフレーズの検出**:
   - あらかじめ設定した悪意のある言葉やフレーズのリストを用意し、投稿内容にそれらが含まれているかをチェックします。これにより、リスクを評価できます。

6. **リアルタイムモニタリング**:
   - 投稿が公開された際に、上記のメトリクスをリアルタイムで計算し、スコアをユーザーに提供することで、炎上を未然に防ぐためのアラートを出すことができます。

これらのアプローチを組み合わせることで、投稿内容がどれくらい悪意があるか、炎上しやすいかを定量的に測定することが可能になります。

7. ハッシュタグの自動生成

8. フォントを自動で選ぶ